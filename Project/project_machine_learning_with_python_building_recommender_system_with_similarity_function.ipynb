{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1 - Unloading and Checking Datasets\n",
    "\n",
    "This time, we will create a recommender system that uses the Content/feature of the movie/entity, then performs calculations on its similarity to one another so that when we point to one movie, we will get several other movies that have similarities with the movie. This time, we will create a recommender system that uses the Content/feature of the movie/entity, then calculates the similarity between one and the other so that when we point to one movie, we will get several other movies that have similarities with the movie. This time, we will create a recommender system that uses the Content/feature of the movie/entity, then calculates the similarity between one and the other so that when we point to one movie, we will get several other movies that have similarities with the movie. This is what we call a Content Based Recommender System.\n",
    "By comparing the similarity of the existing plot and the existing genre, when the audience prefers the movie Narnia, then this content-based recommender system will also recommend movies like Harry Potter or The Lords of The Rings which have similar genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/title.basics.tsv', sep='\\t' ) #for saving title_basics.tsv\n",
    "rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/title.ratings.tsv', sep='\\t') #for saving title.ratings.tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tconst  titleType                                      primaryTitle  \\\n",
      "0  tt0221078      short                         Circle Dance, Ute Indians   \n",
      "1  tt8862466  tvEpisode  ¡El #TeamOsos va con todo al \"Reality del amor\"!   \n",
      "2  tt7157720  tvEpisode                                     Episode #3.41   \n",
      "3  tt2974998  tvEpisode                         Episode dated 16 May 1987   \n",
      "4  tt2903620  tvEpisode                  Frances Bavier: Aunt Bee Retires   \n",
      "\n",
      "                                      originalTitle  isAdult startYear  \\\n",
      "0                         Circle Dance, Ute Indians        0      1898   \n",
      "1  ¡El #TeamOsos va con todo al \"Reality del amor\"!        0      2018   \n",
      "2                                     Episode #3.41        0      2016   \n",
      "3                         Episode dated 16 May 1987        0      1987   \n",
      "4                  Frances Bavier: Aunt Bee Retires        0      1973   \n",
      "\n",
      "  endYear runtimeMinutes             genres  \n",
      "0      \\N             \\N  Documentary,Short  \n",
      "1      \\N             \\N       Comedy,Drama  \n",
      "2      \\N             29   Comedy,Game-Show  \n",
      "3      \\N             \\N               News  \n",
      "4      \\N             \\N        Documentary  \n"
     ]
    }
   ],
   "source": [
    "print(movie_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9025 entries, 0 to 9024\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   tconst          9025 non-null   object\n",
      " 1   titleType       9025 non-null   object\n",
      " 2   primaryTitle    9011 non-null   object\n",
      " 3   originalTitle   9011 non-null   object\n",
      " 4   isAdult         9025 non-null   int64 \n",
      " 5   startYear       9025 non-null   object\n",
      " 6   endYear         9025 non-null   object\n",
      " 7   runtimeMinutes  9025 non-null   object\n",
      " 8   genres          9014 non-null   object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 634.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(movie_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tconst             0\n",
      "titleType          0\n",
      "primaryTitle      14\n",
      "originalTitle     14\n",
      "isAdult            0\n",
      "startYear          0\n",
      "endYear            0\n",
      "runtimeMinutes     0\n",
      "genres            11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(movie_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          tconst  titleType primaryTitle originalTitle  isAdult startYear  \\\n",
      "9000  tt10790040  tvEpisode          NaN           NaN        0      2019   \n",
      "9001  tt10891902  tvEpisode          NaN           NaN        0      2020   \n",
      "9002  tt11737860  tvEpisode          NaN           NaN        0      2020   \n",
      "9003  tt11737862  tvEpisode          NaN           NaN        0      2020   \n",
      "9004  tt11737866  tvEpisode          NaN           NaN        0      2020   \n",
      "9005  tt11737872  tvEpisode          NaN           NaN        0      2020   \n",
      "9006  tt11737874  tvEpisode          NaN           NaN        0      2020   \n",
      "9007   tt1971246  tvEpisode          NaN           NaN        0      2011   \n",
      "9008   tt2067043  tvEpisode          NaN           NaN        0      1965   \n",
      "9009   tt4404732  tvEpisode          NaN           NaN        0      2015   \n",
      "9010   tt5773048  tvEpisode          NaN           NaN        0      2015   \n",
      "9011   tt8473688  tvEpisode          NaN           NaN        0      1987   \n",
      "9012   tt8541336  tvEpisode          NaN           NaN        0      2018   \n",
      "9013   tt9824302  tvEpisode          NaN           NaN        0      2016   \n",
      "\n",
      "     endYear runtimeMinutes                genres  \n",
      "9000      \\N             \\N                    \\N  \n",
      "9001      \\N             \\N                 Crime  \n",
      "9002      \\N             \\N  Comedy,Drama,Romance  \n",
      "9003      \\N             \\N  Comedy,Drama,Romance  \n",
      "9004      \\N             \\N  Comedy,Drama,Romance  \n",
      "9005      \\N             \\N                    \\N  \n",
      "9006      \\N             \\N  Comedy,Drama,Romance  \n",
      "9007      \\N             \\N             Biography  \n",
      "9008      \\N             \\N                 Music  \n",
      "9009      \\N             \\N                Comedy  \n",
      "9010      \\N             \\N             Talk-Show  \n",
      "9011      \\N             \\N                 Drama  \n",
      "9012      \\N             \\N    Reality-TV,Romance  \n",
      "9013      \\N             \\N           Documentary  \n"
     ]
    }
   ],
   "source": [
    "print(movie_df.loc[(movie_df['primaryTitle'].isnull()) | (movie_df['originalTitle'].isnull())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9011\n"
     ]
    }
   ],
   "source": [
    "movie_df = movie_df.loc[(movie_df['primaryTitle'].notnull()) & (movie_df['originalTitle'].notnull())]\n",
    "print(len(movie_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          tconst  titleType  \\\n",
      "9014  tt10233364  tvEpisode   \n",
      "9015  tt10925142  tvEpisode   \n",
      "9016  tt10970874  tvEpisode   \n",
      "9017  tt11670006  tvEpisode   \n",
      "9018  tt11868642  tvEpisode   \n",
      "9019   tt2347742  tvEpisode   \n",
      "9020   tt3984412  tvEpisode   \n",
      "9021   tt8740950  tvEpisode   \n",
      "9022   tt9822816  tvEpisode   \n",
      "9023   tt9900062  tvEpisode   \n",
      "9024   tt9909210  tvEpisode   \n",
      "\n",
      "                                           primaryTitle originalTitle  \\\n",
      "9014  Rolling in the Deep Dish\\tRolling in the Deep ...             0   \n",
      "9015  The IMDb Show on Location: Star Wars Galaxy's ...             0   \n",
      "9016  Die Bauhaus-Stadt Tel Aviv - Vorbild für die M...             0   \n",
      "9017  ...ein angenehmer Unbequemer...\\t...ein angene...             0   \n",
      "9018  GGN Heavyweight Championship Lungs With Mike T...             0   \n",
      "9019  No sufras por la alergia esta primavera\\tNo su...             0   \n",
      "9020  I'm Not Going to Come Last, I'm Just Going to ...             0   \n",
      "9021  Weight Loss Resolution Restart - Ins & Outs of...             0   \n",
      "9022  Zwischen Vertuschung und Aufklärung - Missbrau...             0   \n",
      "9023  The Direction of Yuu's Love: Hings Aren't Goin...             0   \n",
      "9024  Politik und/oder Moral - Wie weit geht das Ver...             0   \n",
      "\n",
      "      isAdult startYear endYear          runtimeMinutes genres  \n",
      "9014     2019        \\N      \\N              Reality-TV    NaN  \n",
      "9015     2019        \\N      \\N               Talk-Show    NaN  \n",
      "9016     2019        \\N      \\N                      \\N    NaN  \n",
      "9017     1981        \\N      \\N             Documentary    NaN  \n",
      "9018     2020        \\N      \\N               Talk-Show    NaN  \n",
      "9019     2004        \\N      \\N                      \\N    NaN  \n",
      "9020     2014        \\N      \\N              Reality-TV    NaN  \n",
      "9021     2015        \\N      \\N              Reality-TV    NaN  \n",
      "9022     2019        \\N      \\N                      \\N    NaN  \n",
      "9023     1994        \\N      \\N  Animation,Comedy,Drama    NaN  \n",
      "9024     2005        \\N      \\N                      \\N    NaN  \n"
     ]
    }
   ],
   "source": [
    "movie_df = movie_df.loc[(movie_df['primaryTitle'].notnull()) & (movie_df['originalTitle'].notnull())]\n",
    "\n",
    "print(movie_df.loc[movie_df['genres'].isnull()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1898. 2018. 2016. 1987. 1973.]\n",
      "[  nan 2005. 1955. 2006. 1999.]\n",
      "[nan 29.  7. 23. 85.]\n"
     ]
    }
   ],
   "source": [
    "movie_df = movie_df.loc[(movie_df['primaryTitle'].notnull()) & (movie_df['originalTitle'].notnull())]\n",
    "movie_df = movie_df.loc[movie_df['genres'].notnull()]\n",
    "\n",
    "#mengubah nilai '\\\\N' pada startYear menjadi np.nan dan cast kolomnya menjadi float64\n",
    "movie_df['startYear'] = movie_df['startYear'].replace('\\\\N', np.nan)\n",
    "movie_df['startYear'] = movie_df['startYear'].astype('float64')\n",
    "print(movie_df['startYear'].unique()[:5])\n",
    "\n",
    "#mengubah nilai '\\\\N' pada endYear menjadi np.nan dan cast kolomnya menjadi float64\n",
    "movie_df['endYear'] = movie_df['endYear'].replace('\\\\N', np.nan)\n",
    "movie_df['endYear'] = movie_df['endYear'].astype('float64')\n",
    "print(movie_df['endYear'].unique()[:5])\n",
    "\n",
    "#mengubah nilai '\\\\N' pada runtimeMinutes menjadi np.nan dan cast kolomnya menjadi float64\n",
    "movie_df['runtimeMinutes'] = movie_df['runtimeMinutes'].replace('\\\\N', np.nan)\n",
    "movie_df['runtimeMinutes'] = movie_df['runtimeMinutes'].astype('float64')\n",
    "print(movie_df['runtimeMinutes'].unique()[:5])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = movie_df.loc[(movie_df['primaryTitle'].notnull()) & (movie_df['originalTitle'].notnull())]\n",
    "movie_df = movie_df.loc[movie_df['genres'].notnull()]\n",
    "movie_df['startYear'] = movie_df['startYear'].replace('\\\\N', np.nan)\n",
    "movie_df['startYear'] = movie_df['startYear'].astype('float64')\n",
    "movie_df['endYear'] = movie_df['endYear'].replace('\\\\N', np.nan)\n",
    "movie_df['endYear'] = movie_df['endYear'].astype('float64')\n",
    "movie_df['runtimeMinutes'] = movie_df['runtimeMinutes'].replace('\\\\N', np.nan)\n",
    "movie_df['runtimeMinutes'] = movie_df['runtimeMinutes'].astype('float64')\n",
    "\n",
    "def transform_to_list(x):\n",
    "    if ',' in x: \n",
    "    #ubah menjadi list apabila ada data pada kolom genre\n",
    "        return x.split(',')\n",
    "    else: \n",
    "    #jika tidak ada data, ubah menjadi list kosong\n",
    "        return []\n",
    "\n",
    "movie_df['genres'] = movie_df['genres'].apply(lambda x: transform_to_list(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rating_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://storage.googleapis.com/dqlab-dataset/title.ratings.tsv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(rating_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:728\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    725\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[1;32m--> 728\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    736\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    737\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:389\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n\u001b[0;32m    388\u001b[0m             compression \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m--> 389\u001b[0m         reader \u001b[38;5;241m=\u001b[39m BytesIO(\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m IOArgs(\n\u001b[0;32m    391\u001b[0m         filepath_or_buffer\u001b[38;5;241m=\u001b[39mreader,\n\u001b[0;32m    392\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    395\u001b[0m         mode\u001b[38;5;241m=\u001b[39mfsspec_mode,\n\u001b[0;32m    396\u001b[0m     )\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_fsspec_url(filepath_or_buffer):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\http\\client.py:481\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 481\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m IncompleteRead:\n\u001b[0;32m    483\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\http\\client.py:630\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[0;32m    624\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[0;32m    625\u001b[0m \n\u001b[0;32m    626\u001b[0m \u001b[38;5;124;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;124;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m amt:\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1276\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1277\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/title.ratings.tsv', sep='\\t')\n",
    "\n",
    "print(rating_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1030009 entries, 0 to 1030008\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count    Dtype  \n",
      "---  ------         --------------    -----  \n",
      " 0   tconst         1030009 non-null  object \n",
      " 1   averageRating  1030009 non-null  float64\n",
      " 2   numVotes       1030009 non-null  int64  \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 23.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(rating_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tconst  titleType              primaryTitle             originalTitle  \\\n",
      "0  tt0043745      short                 Lion Down                 Lion Down   \n",
      "1  tt0167491      video         Wicked Covergirls         Wicked Covergirls   \n",
      "2  tt6574096  tvEpisode      Shadow Play - Part 2      Shadow Play - Part 2   \n",
      "3  tt6941700  tvEpisode              RuPaul Roast              RuPaul Roast   \n",
      "4  tt7305674      video  UCLA Track & Field Promo  UCLA Track & Field Promo   \n",
      "\n",
      "   isAdult  startYear  endYear  runtimeMinutes  \\\n",
      "0        0     1951.0      NaN             7.0   \n",
      "1        1     1998.0      NaN            85.0   \n",
      "2        0     2017.0      NaN            22.0   \n",
      "3        0     2017.0      NaN             NaN   \n",
      "4        0     2017.0      NaN             NaN   \n",
      "\n",
      "                           genres  averageRating  numVotes  \n",
      "0     [Animation, Comedy, Family]            7.1       459  \n",
      "1                              []            5.7         7  \n",
      "2  [Adventure, Animation, Comedy]            8.5       240  \n",
      "3                              []            8.0        11  \n",
      "4                  [Short, Sport]            9.7         7  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1376 entries, 0 to 1375\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   tconst          1376 non-null   object \n",
      " 1   titleType       1376 non-null   object \n",
      " 2   primaryTitle    1376 non-null   object \n",
      " 3   originalTitle   1376 non-null   object \n",
      " 4   isAdult         1376 non-null   int64  \n",
      " 5   startYear       1376 non-null   float64\n",
      " 6   endYear         26 non-null     float64\n",
      " 7   runtimeMinutes  1004 non-null   float64\n",
      " 8   genres          1376 non-null   object \n",
      " 9   averageRating   1376 non-null   float64\n",
      " 10  numVotes        1376 non-null   int64  \n",
      "dtypes: float64(4), int64(2), object(5)\n",
      "memory usage: 118.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "movie_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/title.basics.tsv', sep='\\t')\n",
    "rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/title.ratings.tsv', sep='\\t')\n",
    "\n",
    "movie_df = movie_df.loc[(movie_df['primaryTitle'].notnull()) & (movie_df['originalTitle'].notnull())]\n",
    "movie_df = movie_df.loc[movie_df['genres'].notnull()]\n",
    "movie_df['startYear'] = movie_df['startYear'].replace('\\\\N', np.nan)\n",
    "movie_df['startYear'] = movie_df['startYear'].astype('float64')\n",
    "movie_df['endYear'] = movie_df['endYear'].replace('\\\\N', np.nan)\n",
    "movie_df['endYear'] = movie_df['endYear'].astype('float64')\n",
    "movie_df['runtimeMinutes'] = movie_df['runtimeMinutes'].replace('\\\\N', np.nan)\n",
    "movie_df['runtimeMinutes'] = movie_df['runtimeMinutes'].astype('float64')\n",
    "\n",
    "def transform_to_list(x):\n",
    "    if ',' in x: \n",
    "        return x.split(',')\n",
    "    else: \n",
    "        return []\n",
    "\n",
    "movie_df['genres'] = movie_df['genres'].apply(lambda x: transform_to_list(x))\n",
    "\n",
    "#Lakukan join pada kedua table\n",
    "movie_rating_df = pd.merge(movie_df, rating_df, on='tconst', how='inner')\n",
    "\n",
    "#Tampilkan 5 data teratas\n",
    "print(movie_rating_df.head())\n",
    "\n",
    "#Tampilkan tipe data dari tiap kolom\n",
    "print(movie_rating_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1004 entries, 0 to 1374\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   tconst          1004 non-null   object \n",
      " 1   titleType       1004 non-null   object \n",
      " 2   primaryTitle    1004 non-null   object \n",
      " 3   originalTitle   1004 non-null   object \n",
      " 4   isAdult         1004 non-null   int64  \n",
      " 5   startYear       1004 non-null   float64\n",
      " 6   endYear         17 non-null     float64\n",
      " 7   runtimeMinutes  1004 non-null   float64\n",
      " 8   genres          1004 non-null   object \n",
      " 9   averageRating   1004 non-null   float64\n",
      " 10  numVotes        1004 non-null   int64  \n",
      "dtypes: float64(4), int64(2), object(5)\n",
      "memory usage: 94.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "movie_df = movie_df.loc[(movie_df['primaryTitle'].notnull()) & (movie_df['originalTitle'].notnull())]\n",
    "movie_df = movie_df.loc[movie_df['genres'].notnull()]\n",
    "movie_df['startYear'] = movie_df['startYear'].replace('\\\\N', np.nan)\n",
    "movie_df['startYear'] = movie_df['startYear'].astype('float64')\n",
    "movie_df['endYear'] = movie_df['endYear'].replace('\\\\N', np.nan)\n",
    "movie_df['endYear'] = movie_df['endYear'].astype('float64')\n",
    "movie_df['runtimeMinutes'] = movie_df['runtimeMinutes'].replace('\\\\N', np.nan)\n",
    "movie_df['runtimeMinutes'] = movie_df['runtimeMinutes'].astype('float64')\n",
    "\n",
    "def transform_to_list(x):\n",
    "    if ',' in x: \n",
    "        return x.split(',')\n",
    "    else: \n",
    "        return []\n",
    "\n",
    "movie_df['genres'] = movie_df['genres'].apply(lambda x: transform_to_list(x))\n",
    "\n",
    "movie_rating_df = pd.merge(movie_df, rating_df, on='tconst', how='inner')\n",
    "movie_rating_df = movie_rating_df.dropna(subset=['startYear','runtimeMinutes'])\n",
    "\n",
    "#Untuk memastikan bahwa sudah tidak ada lagi nilai NULL\n",
    "print(movie_rating_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.829581673306773\n"
     ]
    }
   ],
   "source": [
    "movie_df = movie_df.loc[(movie_df['primaryTitle'].notnull()) & (movie_df['originalTitle'].notnull())]\n",
    "movie_df = movie_df.loc[movie_df['genres'].notnull()]\n",
    "movie_df['startYear'] = movie_df['startYear'].replace('\\\\N', np.nan)\n",
    "movie_df['startYear'] = movie_df['startYear'].astype('float64')\n",
    "movie_df['endYear'] = movie_df['endYear'].replace('\\\\N', np.nan)\n",
    "movie_df['endYear'] = movie_df['endYear'].astype('float64')\n",
    "movie_df['runtimeMinutes'] = movie_df['runtimeMinutes'].replace('\\\\N', np.nan)\n",
    "movie_df['runtimeMinutes'] = movie_df['runtimeMinutes'].astype('float64')\n",
    "\n",
    "def transform_to_list(x):\n",
    "    if ',' in x: \n",
    "        return x.split(',')\n",
    "    else: \n",
    "        return []\n",
    "\n",
    "movie_df['genres'] = movie_df['genres'].apply(lambda x: transform_to_list(x))\n",
    "\n",
    "movie_rating_df = pd.merge(movie_df, rating_df, on='tconst', how='inner')\n",
    "movie_rating_df = movie_rating_df.dropna(subset=['startYear','runtimeMinutes'])\n",
    "\n",
    "C = movie_rating_df['averageRating'].mean()\n",
    "print(C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229.0\n"
     ]
    }
   ],
   "source": [
    "m = movie_rating_df['numVotes'].quantile(0.8)\n",
    "print(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tconst  titleType          primaryTitle         originalTitle  isAdult  \\\n",
      "0  tt0043745      short             Lion Down             Lion Down        0   \n",
      "1  tt0167491      video     Wicked Covergirls     Wicked Covergirls        1   \n",
      "2  tt6574096  tvEpisode  Shadow Play - Part 2  Shadow Play - Part 2        0   \n",
      "5  tt2262289      movie               The Pin               The Pin        0   \n",
      "6  tt0874027  tvEpisode         Episode #32.9         Episode #32.9        0   \n",
      "\n",
      "   startYear  endYear  runtimeMinutes genres  averageRating  numVotes  \\\n",
      "0     1951.0      NaN             7.0     []            7.1       459   \n",
      "1     1998.0      NaN            85.0     []            5.7         7   \n",
      "2     2017.0      NaN            22.0     []            8.5       240   \n",
      "5     2013.0      NaN            85.0     []            7.7        27   \n",
      "6     2006.0      NaN            29.0     []            8.0         8   \n",
      "\n",
      "      score  \n",
      "0  7.009992  \n",
      "1  6.796077  \n",
      "2  7.684380  \n",
      "5  6.921384  \n",
      "6  6.869089  \n"
     ]
    }
   ],
   "source": [
    "def imdb_weighted_rating(df, var=0.8):\n",
    "    v = df['numVotes']\n",
    "    R = df['averageRating']\n",
    "    C = df['averageRating'].mean()\n",
    "    m = df['numVotes'].quantile(var)\n",
    "    df['score'] = (v/(m+v))*R + (m/(m+v))*C #Rumus IMDb \n",
    "    return df['score']\n",
    "    \n",
    "imdb_weighted_rating(movie_rating_df)\n",
    "\n",
    "#melakukan pengecekan dataframe\n",
    "print(movie_rating_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         tconst  titleType                                   primaryTitle  \\\n",
      "68    tt4110822  tvEpisode                                  S.O.S. Part 2   \n",
      "236   tt2200252      video                    Attack of the Clones Review   \n",
      "1181  tt7697962  tvEpisode            Chapter Seventeen: The Missionaries   \n",
      "326   tt7124590  tvEpisode            Chapter Thirty-Four: Judgment Night   \n",
      "1045  tt0533506  tvEpisode                                       The Prom   \n",
      "71    tt8399426  tvEpisode                                        Savages   \n",
      "1234  tt2843830  tvEpisode                                          VIII.   \n",
      "1087  tt4295140   tvSeries                                   Chef's Table   \n",
      "1054  tt2503932  tvEpisode                                Trial and Error   \n",
      "448   tt0337566      video                       AC/DC: Live at Donington   \n",
      "624   tt0620159  tvEpisode                                     Strike Out   \n",
      "1281  tt3166390  tvEpisode                         Looking for a Plus-One   \n",
      "314   tt0954759  tvEpisode                                   Ben Franklin   \n",
      "189   tt5661506      video            Florence + the Machine: The Odyssey   \n",
      "151   tt3954426  tvEpisode                                Bleeding Kansas   \n",
      "1344  tt6644294  tvEpisode                 The Hostile Hospital: Part Two   \n",
      "1242  tt3677742  tvSpecial  Saturday Night Live: 40th Anniversary Special   \n",
      "1217  tt3642464  tvEpisode                                    Giant Woman   \n",
      "544   tt0734655  tvEpisode                              The Little People   \n",
      "49    tt9119838  tvEpisode                      Parisian Legend Has It...   \n",
      "357   tt4084774  tvEpisode                           Trial and Punishment   \n",
      "1111  tt4174072  tvEpisode                     Immortal Emerges from Cave   \n",
      "790   tt4279086  tvEpisode                       And Santa's Midnight Run   \n",
      "972   tt0048028      movie                                   East of Eden   \n",
      "819   tt0032156      movie            The Story of the Last Chrysanthemum   \n",
      "\n",
      "                                      originalTitle  isAdult  startYear  \\\n",
      "68                                    S.O.S. Part 2        0     2015.0   \n",
      "236                     Attack of the Clones Review        0     2010.0   \n",
      "1181            Chapter Seventeen: The Missionaries        0     2019.0   \n",
      "326             Chapter Thirty-Four: Judgment Night        0     2018.0   \n",
      "1045                                       The Prom        0     1999.0   \n",
      "71                                          Savages        0     2018.0   \n",
      "1234                                          VIII.        0     2014.0   \n",
      "1087                                   Chef's Table        0     2015.0   \n",
      "1054                                Trial and Error        0     2013.0   \n",
      "448                        AC/DC: Live at Donington        0     1992.0   \n",
      "624                                      Strike Out        0     2000.0   \n",
      "1281                         Looking for a Plus-One        0     2014.0   \n",
      "314                                    Ben Franklin        0     2007.0   \n",
      "189             Florence + the Machine: The Odyssey        0     2016.0   \n",
      "151                                 Bleeding Kansas        0     2014.0   \n",
      "1344                 The Hostile Hospital: Part Two        0     2018.0   \n",
      "1242  Saturday Night Live: 40th Anniversary Special        0     2015.0   \n",
      "1217                                    Giant Woman        0     2014.0   \n",
      "544                               The Little People        0     1962.0   \n",
      "49                        Parisian Legend Has It...        0     2019.0   \n",
      "357                            Trial and Punishment        0     2015.0   \n",
      "1111                     Immortal Emerges from Cave        0     2017.0   \n",
      "790                        And Santa's Midnight Run        0     2014.0   \n",
      "972                                    East of Eden        0     1955.0   \n",
      "819                              Zangiku monogatari        0     1939.0   \n",
      "\n",
      "      endYear  runtimeMinutes genres  averageRating  numVotes     score  \n",
      "68        NaN            43.0     []            9.4      3820  9.254624  \n",
      "236       NaN            86.0     []            9.3      1411  8.955045  \n",
      "1181      NaN            54.0     []            9.2      1536  8.892450  \n",
      "326       NaN            42.0     []            9.1      1859  8.850993  \n",
      "1045      NaN            60.0     []            8.9      2740  8.740308  \n",
      "71        NaN            58.0     []            9.0      1428  8.700045  \n",
      "1234      NaN            57.0     []            8.9      1753  8.660784  \n",
      "1087      NaN            50.0     []            8.6     12056  8.566998  \n",
      "1054      NaN            43.0     []            8.6      2495  8.451165  \n",
      "448       NaN           120.0     []            8.5      1343  8.256663  \n",
      "624       NaN            30.0     []            8.7       401  8.020118  \n",
      "1281      NaN            28.0     []            8.7       396  8.014679  \n",
      "314       NaN            21.0     []            8.1      2766  8.002863  \n",
      "189       NaN            49.0     []            8.8       330  7.992798  \n",
      "151       NaN            42.0     []            8.6       437  7.991253  \n",
      "1344      NaN            40.0     []            8.3       812  7.976536  \n",
      "1242      NaN           106.0     []            8.1      1931  7.965312  \n",
      "1217      NaN            11.0     []            8.4       566  7.947641  \n",
      "544       NaN            25.0     []            8.1      1559  7.937290  \n",
      "49        NaN            42.0     []            8.9       263  7.936330  \n",
      "357       NaN            56.0     []            8.8       289  7.928908  \n",
      "1111      NaN            53.0     []            8.0      2898  7.914287  \n",
      "790       NaN            42.0     []            8.2       823  7.901687  \n",
      "972       NaN           118.0     []            7.9     38543  7.893678  \n",
      "819       NaN           143.0     []            7.9      2974  7.823470  \n"
     ]
    }
   ],
   "source": [
    "movie_rating_df = movie_rating_df.dropna(subset=['startYear','runtimeMinutes'])\n",
    "\n",
    "C = movie_rating_df['averageRating'].mean()\n",
    "m = movie_rating_df['numVotes'].quantile(0.8)\n",
    "\n",
    "def imdb_weighted_rating(df, var=0.8):\n",
    "    v = df['numVotes']\n",
    "    R = df['averageRating']\n",
    "    C = df['averageRating'].mean()\n",
    "    m = df['numVotes'].quantile(var)\n",
    "    df['score'] = (v/(m+v))*R + (m/(m+v))*C\n",
    "    return df['score']\n",
    "    \n",
    "imdb_weighted_rating(movie_rating_df)\n",
    "\n",
    "def simple_recommender(df, top=100):\n",
    "    df = df.loc[df['numVotes'] >= m]\n",
    "    df = df.sort_values(by='score', ascending=False) #urutkan dari nilai tertinggi ke terendah\n",
    "    \n",
    "    #Ambil data 100 teratas\n",
    "    df = df[:top]\n",
    "    return df\n",
    "    \n",
    "#Ambil data 25 teratas     \n",
    "print(simple_recommender(movie_rating_df, top=25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [tconst, titleType, primaryTitle, originalTitle, isAdult, startYear, endYear, runtimeMinutes, genres, averageRating, numVotes, score]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df = movie_rating_df.copy()\n",
    "\n",
    "def user_prefer_recommender(df, ask_adult, ask_start_year, ask_genre, top=100):\n",
    "    #ask_adult = yes/no\n",
    "    if ask_adult.lower() == 'yes':\n",
    "        df = df.loc[df['isAdult'] == 1]\n",
    "    elif ask_adult.lower() == 'no':\n",
    "        df = df.loc[df['isAdult'] == 0]\n",
    "\n",
    "    #ask_start_year = numeric\n",
    "    df = df.loc[df['startYear'] >= int(ask_start_year)]\n",
    "\n",
    "    #ask_genre = 'all' atau yang lain\n",
    "    if ask_genre.lower() == 'all':\n",
    "        df = df\n",
    "    else:\n",
    "        def filter_genre(x):\n",
    "            if ask_genre.lower() in str(x).lower():\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        df = df.loc[df['genres'].apply(lambda x: filter_genre(x))]\n",
    "\n",
    "    df = df.loc[df['numVotes'] >= m]  #Mengambil film dengan numVotes yang lebih besar atau sama dengan nilai m \n",
    "    df = df.sort_values(by='score', ascending=False)\n",
    "    \n",
    "    #jika kamu hanya ingin mengambil 100 teratas\n",
    "    df = df[:top]\n",
    "    return df\n",
    "\n",
    "print(user_prefer_recommender(df,\n",
    "                       ask_adult = 'no',\n",
    "                        ask_start_year = 2000,\n",
    "                       ask_genre = 'drama'\n",
    "                       ))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
